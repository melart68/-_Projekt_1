# Проект: Анализ резюме из HeadHunter

<img src= images/hh.jpg alt="drawing" style="width:400px;"/>

## Оглавление

[1. Описание проекта](.README.md#Описание-проекта)  
[2. Какой кейс решаем?](.README.md#Какой-кейс-решаем)  
[3. Краткая информация о данных](.README.md#Краткая-информация-о-данных)  
[4. Этапы работы над проектом](.README.md#Этапы-работы-над-проектом)  
[5. Результат](.README.md#Результат)
[6. Выводы](.README.md#Выводы)
[7. Использованные инструменты и библиотеки](.README.md#Использованные-инструменты-и-библиотеки)
[8. Ссылки на данные](.README.md#Ссылки-на-данные)

### Описание проекта

Нам предстоит решить часть бизнес-задачи, база резюме выгруженная с сайта поиска вакансий hh.ru.
Проблематика: часть соискателей не указывает желаемую заработную плату, когда составляет своё резюме. Что является помехой для рекомендательной системы HeadHunter, которая подбирает соискателям список наиболее подходящих вакансий, а работодателям — список наиболее подходящих специалистов.
Компания HeadHunter хочет построить модель, которая бы автоматически определяла примерный уровень заработной платы, подходящей пользователю, исходя из информации, которую он указал о себе. Но прежде чем построить модель, данные необходимо преобразовать, исследовать и очистить.

[к оглавлению](.README.md#Оглавление)

### Какой кейс решаем?

1. Базовый анализ структуры данных
2. Преобразование данных
3. Разведывательный анализ
4. Очистка данных

[к оглавлению](.README.md#Оглавление)

### Этапы работы над проектом

1. Чтение и первоначальный анализ данных.
2. Преобразование данных т.е некоторые категоримм были представлены совместно, для далнейщей работы их отделили и выделили в категории.
3. Построили графики зависимостей и зависимостей между признаками.
4. Очистили данные от дубликатов, пропусков и выбрасов.  

[к оглавлению](.README.md#Оглавление)

### Результат

1. Определили зависимость желаемой зарплаты соискателей от местоположения, уровня образования, города проживания и наконец от пола.
2. Определили самую попульярную вакансию.
3. С помощью z-отклонения определили является ли распределение логнормальным.

[к оглавлению](.README.md#Оглавление)

### Выводы

После очистки данных от дупликатов, ручного нахождения и удаления выбрасов, корректировки данных, с помощью метода z-отклонения очистки данных получено логнормальное распределение, которое имеет права стороную асмметрию.

Получен практический опыт по работе с реальными данными

[к оглавлению](.README.md#Оглавление)

### Использованные инструменты и библиотеки

* ### numpy

* ### pandas

* ### seaborn

* ### plotly

* ### matplotlib

[к оглавлению](.README.md#Оглавление)

## **Ссылки на данные**


* ### [Данные валют](https://drive.google.com/file/d/12vHP5RpOscpP2KS5vfo7Yvf0CKn6nqWB/view?usp=drive_link)

* ### [Данные поиска вакансий](https://drive.google.com/file/d/1td0op0UcKM3BOQ_3qrrQMangkkJpJh3F/view?usp=drive_link)

[к оглавлению](.README.md#Оглавление)
